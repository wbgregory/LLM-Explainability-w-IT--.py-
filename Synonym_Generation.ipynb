{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ace', 'adept', 'champion', 'sensation', 'maven', 'mavin', 'virtuoso', 'genius', 'hotshot', 'star', 'superstar', 'whiz', 'whizz', 'wizard', 'wiz']\n",
      "['whiz']\n",
      "['whizz', 'whiz', 'whirr', 'whir', 'birr', 'purr']\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "# for synset in wordnet.synsets('whiz'): \n",
    "#     print(synset.lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\william.gregory\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['answer ', 'solution', 'suffice', 'answer'], ['yes ', 'yes'], ['or ', 'oregon', 'operating_room', 'or'], ['no', 'nobelium', 'no ']]\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import csv\n",
    "\n",
    "syn_sentence = 'answer yes or no'\n",
    "#syn_sentence = 'can you drink alcoholic drink in populace in kingdom of denmark'\n",
    "extra_sent = 'can you do mathematical calculations at school'\n",
    "trial_sent = 'is it possible to listen to music in a car'\n",
    "\n",
    "# potential sentences: 'can you steal from a store in canada?'\n",
    "\n",
    "def syn_generator(synonym_sentence: str):\n",
    "    tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "    components = tokenizer.tokenize(synonym_sentence)\n",
    "    highest_sim_level = 0\n",
    "    most_acc_word = ''\n",
    "    synonyms = dict()\n",
    "    split_sentence = synonym_sentence.split()\n",
    "    nested_accumulator = 0\n",
    "    nested_syns = [ [] for num in range(len(components)) ]\n",
    "    nested_accumulator = 0\n",
    "    original_accumulator = 0\n",
    "    for word in components:\n",
    "        syns = wordnet.synsets(word)\n",
    "        synonyms[word] = syns\n",
    "        nested_syns[original_accumulator].append(word)\n",
    "        nested_syns[original_accumulator].append(word + ' ')\n",
    "        original_accumulator += 1\n",
    "    for key, value in synonyms.items():\n",
    "        for syn in value:\n",
    "            syn_list = str(syn)\n",
    "            syn_list = syn_list.replace(\"Synset('\", \"\")\n",
    "            cut_off = syn_list.index('.')\n",
    "            isolated_syn = str(syn_list[0:cut_off])\n",
    "            nested_syns[nested_accumulator].append(isolated_syn)\n",
    "        nested_syns[nested_accumulator] = list(set(nested_syns[nested_accumulator]))\n",
    "        if len(nested_syns[nested_accumulator]) == 0:\n",
    "            nested_syns[nested_accumulator].append(key)\n",
    "            nested_syns[nested_accumulator].append(key + ' ')\n",
    "        elif len(nested_syns[nested_accumulator]) == 1:\n",
    "            nested_syns[nested_accumulator].append(nested_syns[nested_accumulator][0] + ' ')\n",
    "        nested_accumulator += 1\n",
    "\n",
    "    return nested_syns\n",
    "\n",
    "sent_array = syn_generator(syn_sentence)\n",
    "print(sent_array)\n",
    "\n",
    "#extra_array = syn_generator(extra_sent)\n",
    "#print(extra_array)\n",
    "# print(syn_generator(syn_sentence))\n",
    "#trial_array = syn_generator(trial_sent)\n",
    "#print(trial_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "(((0, 3), ('answer', 'no')),) (((2, 3), ('operating_room', 'no')),)\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "(((0, 2), ('solution', 'or')),) (((2, 3), ('or', 'no ')),)\n",
      "52\n",
      "53\n",
      "(((0, 2), ('suffice', 'oregon')),) (((0, 3), ('suffice', 'no ')),)\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "57\n",
      "[['answer ', 'yes ', 'operating_room', 'nobelium'], ['solution', 'yes', 'or', 'no'], ['suffice', 'yes ', 'oregon', 'no '], ['solution', 'yes', 'or', 'no'], ['answer', 'yes ', 'or ', 'no '], ['answer ', 'yes ', 'or ', 'no '], ['solution', 'yes', 'or ', 'no'], ['suffice', 'yes ', 'or ', 'no '], ['suffice', 'yes', 'oregon', 'no'], ['answer ', 'yes', 'oregon', 'no'], ['solution', 'yes', 'operating_room', 'no'], ['suffice', 'yes', 'oregon', 'nobelium'], ['solution', 'yes', 'or', 'no'], ['solution', 'yes ', 'oregon', 'nobelium'], ['solution', 'yes', 'or', 'no '], ['answer ', 'yes', 'operating_room', 'no '], ['answer', 'yes ', 'operating_room', 'nobelium'], ['answer', 'yes', 'operating_room', 'no '], ['solution', 'yes ', 'operating_room', 'no '], ['answer ', 'yes ', 'or ', 'no'], ['solution', 'yes ', 'or', 'nobelium'], ['answer', 'yes', 'or', 'nobelium'], ['answer', 'yes ', 'or ', 'no'], ['answer', 'yes ', 'operating_room', 'no '], ['solution', 'yes', 'operating_room', 'nobelium'], ['answer', 'yes ', 'oregon', 'no '], ['solution', 'yes', 'or ', 'no '], ['suffice', 'yes', 'or', 'nobelium'], ['answer ', 'yes ', 'oregon', 'no '], ['answer ', 'yes ', 'operating_room', 'no '], ['answer ', 'yes', 'operating_room', 'nobelium'], ['answer ', 'yes', 'operating_room', 'nobelium'], ['solution', 'yes ', 'or', 'no '], ['answer', 'yes', 'or', 'no'], ['suffice', 'yes', 'or ', 'no'], ['suffice', 'yes', 'operating_room', 'no'], ['solution', 'yes', 'oregon', 'nobelium'], ['suffice', 'yes', 'operating_room', 'nobelium'], ['answer ', 'yes', 'operating_room', 'nobelium'], ['suffice', 'yes', 'operating_room', 'no '], ['answer ', 'yes', 'operating_room', 'no'], ['solution', 'yes', 'operating_room', 'no'], ['answer', 'yes', 'or ', 'nobelium'], ['answer', 'yes ', 'or ', 'nobelium'], ['suffice', 'yes ', 'or', 'no '], ['answer ', 'yes', 'or', 'no'], ['answer', 'yes ', 'or ', 'no '], ['solution', 'yes ', 'or', 'no '], ['answer', 'yes ', 'oregon', 'nobelium'], ['suffice', 'yes', 'or', 'no '], ['answer ', 'yes', 'or', 'nobelium'], ['answer ', 'yes', 'or ', 'nobelium'], ['answer ', 'yes ', 'or', 'no'], ['answer', 'yes ', 'or ', 'nobelium'], ['suffice', 'yes', 'oregon', 'no '], ['answer ', 'yes', 'or ', 'no '], ['suffice', 'yes', 'or ', 'nobelium']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "#from Gregory_CoveringArray import verify_covering_array\n",
    "from LocatingArray import locating_array_verifier\n",
    "import pprint\n",
    "import math\n",
    "from math import comb\n",
    "\n",
    "\n",
    "t = 2\n",
    "d = 1\n",
    "lamb = 2\n",
    "#k = len(sent_array)\n",
    "def determine_N(nested_syns_list, lamb, t):\n",
    "    lengths_of_lists = list(map(len, nested_syns_list))\n",
    "    ordered_lengths = sorted(lengths_of_lists, reverse = True)\n",
    "    N = math.prod(ordered_lengths[0:t]) * lamb\n",
    "    return N\n",
    "\n",
    "def sentence_covering_array(values, N):\n",
    "    ca_list = []\n",
    "    for _ in range(N):\n",
    "        new_rows = list(map(random.choice, values))\n",
    "        ca_list.append(new_rows)\n",
    "    return ca_list\n",
    "\n",
    "def repeat(n_syns, N, t, d, lamb):\n",
    "    tested_amount = 0\n",
    "    print(N)\n",
    "    while tested_amount != 30:\n",
    "        var = sentence_covering_array(n_syns, N)\n",
    "        test = var\n",
    "        if locating_array_verifier(var, t, list(map(len, n_syns)), d, n_syns, lamb):\n",
    "            print(N)\n",
    "            return test\n",
    "        else:\n",
    "            tested_amount += 1\n",
    "    if tested_amount == 30:\n",
    "        N += 1\n",
    "        return repeat(n_syns, N, t, d, lamb)\n",
    "\n",
    "tt = repeat(sent_array, determine_N(sent_array, lamb, t), t, d, lamb)\n",
    "print(tt)\n",
    "\n",
    "#extra = repeat(sent_array, determine_N(extra_array, lamb, t), t, d, lamb)\n",
    "#print(extra)\n",
    "\n",
    "#trial = repeat(trial_array, determine_N(trial_array, lamb, t), t, d, lamb)\n",
    "#print(trial)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##backup code:\n",
    "\n",
    "# tokenizer = RegexpTokenizer(\"[\\w']+\")\n",
    "# synonym_sentence = 'can you drink alcoholic drink in populace in kingdom of denmark'\n",
    "# components = tokenizer.tokenize(synonym_sentence)\n",
    "# highest_sim_level = 0\n",
    "# most_acc_word = ''\n",
    "# synonyms = dict()\n",
    "# split_sentence = synonym_sentence.split()\n",
    "# nested_accumulator = 0\n",
    "# nested_syns = [ [] for num in range(len(components)) ]\n",
    "# nested_accumulator = 0\n",
    "# original_accumulator = 0\n",
    "# for word in components:\n",
    "#     syns = wordnet.synsets(word)\n",
    "#     synonyms[word] = syns\n",
    "#     nested_syns[original_accumulator].append(word)\n",
    "#     nested_syns[original_accumulator].append(word + ' ')\n",
    "#     #nested_syns[original_accumulator].append(word)\n",
    "#     original_accumulator += 1\n",
    "# print(synonyms.items())\n",
    "# for key, value in synonyms.items():\n",
    "#     file_name = str(key) + '_syns'\n",
    "#     with open(file_name, 'w') as synonym_file:\n",
    "#         for syn in value:\n",
    "#             synonym_file.write(str(syn) + '\\n')\n",
    "#         for syn in value:\n",
    "#             syn_list = str(syn)\n",
    "#             syn_list = syn_list.replace(\"Synset('\", \"\")\n",
    "#             cut_off = syn_list.index('.')\n",
    "#             isolated_syn = str(syn_list[0:cut_off])\n",
    "#             nested_syns[nested_accumulator].append(isolated_syn)\n",
    "#         nested_syns[nested_accumulator] = list(set(nested_syns[nested_accumulator]))\n",
    "#         print(key, value)\n",
    "#         if len(nested_syns[nested_accumulator]) == 0:\n",
    "#             nested_syns[nested_accumulator].append(key)\n",
    "#             nested_syns[nested_accumulator].append(key + ' ')\n",
    "#         elif len(nested_syns[nested_accumulator]) == 1:\n",
    "#             nested_syns[nested_accumulator].append(nested_syns[nested_accumulator][0] + ' ')\n",
    "#         print(nested_syns[nested_accumulator])\n",
    "#         nested_accumulator += 1\n",
    "# print(nested_syns)\n",
    "\n",
    "\n",
    "\n",
    "#extra code storage\n",
    "\n",
    "\n",
    "\n",
    "# synonym_sentence = 'can you drink alcoholic drink in populace in kingdom of denmark?'\n",
    "# highest_sim_level = 0\n",
    "# most_acc_word = ''\n",
    "# split_sentence = synonym_sentence.strip()\n",
    "# for word in split_sentence:\n",
    "#     for synset in wordnet.synsets(word):\n",
    "#         synonym_list = word + '_synonym_list'\n",
    "#         syn_file = open(synonym_list, 'w+')\n",
    "#         similar_words = synset.lemma_names()\n",
    "#         string_similar_words = str(similar_words)\n",
    "#         syn_file.write(string_similar_words)\n",
    "#         for added_word in syn_file:\n",
    "#             added_word = added_word.strip()\n",
    "#             w1 = wordnet.synset(word)\n",
    "#             w2 = wordnet.synset(added_word) \n",
    "#             sim_level = (w1.wup_similarity(w2)) \n",
    "#             added_word_string = str(added_word)\n",
    "#             if sim_level > highest_sim_level:\n",
    "#                 highest_sim_level += sim_level\n",
    "#                 most_acc_word = added_word_string\n",
    "# print(highest_sim_level)\n",
    "# print(most_acc_word)\n",
    "\n",
    "        #print(nested_syns[nested_accumulator])\n",
    "        #print(len(nested_syns[nested_accumulator]))\n",
    "\n",
    "#extra_array = syn_generator(extra_sent)\n",
    "#print(extra_array)\n",
    "# print(syn_generator(syn_sentence))\n",
    "#trial_array = syn_generator(trial_sent)\n",
    "#print(trial_array)\n",
    "\n",
    "\n",
    "\n",
    "#add original word to index portion of synonyms (no empty lists)\n",
    "\n",
    "# take the number two largest amounts of synonyms, multiply them by each other and start N at that point.\n",
    "\n",
    "\n",
    "#math.log()\n",
    "\n",
    "\n",
    "#v = max()\n",
    "#a = sqrt(((1-p)**(2*lamb) - (p**(2*lamb))))\n",
    "#p = 1/v**t\n",
    "\n",
    "#portion2 = (1 + (comb(k, t) * (v**t) * a * (1-p))^(1/lamb)) / math.log(1 / (1-p))\n",
    "\n",
    "#CAN = 1 + (lamb * math.e) / ((math.e - 1) * math.log(1 / (1-p))) * (1 + math.log(portion2))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# tested_amount = 0\n",
    "# if locating_array_verifier(sentence_covering_array(nested_syns, N), t, list(map(len, nested_syns)), d, nested_syns, lamb):\n",
    "#     print(f'This is a locating array!')\n",
    "# else:\n",
    "#     while tested_amount != 10:\n",
    "#         if locating_array_verifier(sentence_covering_array(nested_syns, N), t, list(map(len, nested_syns)), d, nested_syns, lamb):\n",
    "#             print(f'This is a locating array!')\n",
    "#     N += 2\n",
    "#     print(nested_syns)\n",
    "#     print(list(map(len, nested_syns)))\n",
    "#     test = locating_array_verifier(sentence_covering_array(nested_syns, N), t, list(map(len, nested_syns)), d, nested_syns, lamb)\n",
    "#     while test != True:\n",
    "#             N *= 2\n",
    "#             var = sentence_covering_array(nested_syns, N)\n",
    "#             test = locating_array_verifier(var, t, list(map(len, nested_syns)), d, nested_syns, lamb)\n",
    "#             print(N)\n",
    "# print(var)\n",
    "# print(len(var))\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
